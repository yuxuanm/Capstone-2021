{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 256 # chunk size 256,512\n",
    "long = 256 # chunk size 256,512\n",
    "def split_array(input_data, lat, long,region):\n",
    "    \"\"\"\n",
    "    Split the whole 3600*1500 array into smaller chunks.\n",
    "    Padding with zeros to make the array be divisible by chunk size.\n",
    "    \n",
    "    Args:\n",
    "        input_data: data of a single day from a eta_t instance\n",
    "        lat: chunk size\n",
    "        long: chunk size\n",
    "    \"\"\"\n",
    "    pad_cols = math.ceil(3600/long)*long - 3600 # number of zero columns adding to the right\n",
    "    pad_rows = math.ceil(1500/lat)*lat - 1500 # number of zero rows adding to the bottom\n",
    "    \n",
    "\n",
    "    input_data=np.pad(input_data,((0,pad_rows),(0,pad_cols)), 'constant',constant_values=(0,0)) # padding with zeros, right & bottom\n",
    "    \n",
    "    l = np.array_split(input_data,len(input_data)/lat,axis=0)\n",
    "    input_data_split = []\n",
    "    for i in range(len(l)):\n",
    "        dd = np.array_split(l[i],len(input_data[0])/long,axis=1)\n",
    "        input_data_split += dd\n",
    "    input_data_split = np.array(input_data_split)\n",
    "    return input_data_split[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in range(184,195):\n",
    "    path_prefix = 'C:/Users/Yuxuan/Desktop/data_256/'\n",
    "    folder = 'dataset_' + str(i)\n",
    "    path = path_prefix + folder\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# l=[1,3,5,6]\n",
    "for ll in [1,3,5,6,8]:\n",
    "    print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 12/12 [14:35<00:00, 72.93s/it]\n",
      "100%|██████████████████████████████████████████| 12/12 [00:01<00:00,  7.10it/s]\n",
      "100%|██████████████████████████████████████████| 12/12 [00:01<00:00,  7.34it/s]\n",
      "100%|██████████████████████████████████████████| 12/12 [00:01<00:00,  7.24it/s]\n",
      "100%|██████████████████████████████████████████| 12/12 [00:01<00:00,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# folder = 'region222' #change folder name for every region\n",
    "num_of_years = 5\n",
    "# region = 222 #change region\n",
    "num_errors = 0\n",
    "error_year = []\n",
    "error_month = []\n",
    "\n",
    "basic_url = 'http://dapds00.nci.org.au/thredds/dodsC/gb6/BRAN/BRAN_2016/OFAM/ocean_eta_t_'\n",
    "year = 2015\n",
    "for i in range(num_of_years):\n",
    "    year += 1\n",
    "    month = 1\n",
    "    for j in tqdm(range(12)):\n",
    "        month += 1\n",
    "        if month > 9:\n",
    "            m = str(month)\n",
    "        else:\n",
    "            m = '0'+str(month)\n",
    "        #print('year: ',year,' month: ',month)\n",
    "        y = str(year)\n",
    "        url = basic_url + y + '_' + m + '.nc'\n",
    "        try:\n",
    "            #data = nc.Dataset(url)\n",
    "            data = xr.open_dataset(url)\n",
    "        except:\n",
    "            num_errors+=1\n",
    "            error_year.append(y)\n",
    "            error_month.append(m)\n",
    "            continue\n",
    "        #variables = data.variables\n",
    "        eta_t = data['eta_t'].to_numpy() #data['eta_t'][:]\n",
    "        size = eta_t.shape[0]\n",
    "        for d in range(size):\n",
    "            eta_t_day_d = eta_t[d]\n",
    "            eta_t_numpy = eta_t_day_d #np.array(eta_t_day_d)\n",
    "\n",
    "\n",
    "            for r in range(0,90):\n",
    "                path_prefix = 'C:/Users/Yuxuan/Desktop/data256/'\n",
    "                folder = 'dataset_' + str(r)\n",
    "                path = path_prefix + folder\n",
    "#                 print(path)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                inputs = split_array(eta_t_numpy,lat,long,r)\n",
    "                inputsx = np.expand_dims(inputs,axis=2)\n",
    "                file_name = path +'/'+ y+'_'+m+'_'+str(d+1)+'.npy'\n",
    "#                 print(file_name)\n",
    "                np.save(file_name,inputsx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
