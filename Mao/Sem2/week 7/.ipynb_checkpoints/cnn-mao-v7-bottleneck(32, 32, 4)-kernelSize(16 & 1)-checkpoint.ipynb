{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51d6bcd",
   "metadata": {},
   "source": [
    "## Important parameters\n",
    "<br>xt_ocean: longitude, length 3600\n",
    "<br>yt_ocean: latitude, length 1500\n",
    "<br> [mind map](https://miro.com/app/board/o9J_lM4N1Pg=/?fromRedirect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1795d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "from tensorflow import keras\n",
    "import xarray,numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e6d28",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6208fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "input_data_split = []\n",
    "for np_name in glob.glob('../raw data/128/dataset_128_N102/*.np[yz]'):\n",
    "    input_data_split.append(np.load(np_name))\n",
    "input_data_split = np.array(input_data_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2f7c3",
   "metadata": {},
   "source": [
    "# Fix Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca0c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_value(input_data):\n",
    "    \"\"\"\n",
    "    input 3d matrix\n",
    "    \"\"\"\n",
    "    for i in range(0,len(input_data)):\n",
    "        arr = input_data[i]\n",
    "        arr[np.isnan(arr)] = 0\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dce738",
   "metadata": {},
   "source": [
    "# Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba3d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(input_data, max_value, min_value):\n",
    "    \"\"\"\n",
    "    input 3d matrix\n",
    "    \"\"\"\n",
    "    for i in range(len(input_data)):\n",
    "        input_data[i] = (input_data[i] - min_value)/(max_value - min_value)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1f398",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "n = 3000 # sample size\n",
    "random.seed(7)\n",
    "input_data_split = np.array(random.sample(input_data_split.tolist(),n))\n",
    "input_data_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d72e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_split = fix_missing_value(input_data_split)\n",
    "max_value = np.amax(input_data_split)\n",
    "min_value = np.amin(input_data_split)\n",
    "input_data_split_scaled = min_max_scale(input_data_split, max_value, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_split_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c60c7",
   "metadata": {},
   "source": [
    "# split train set & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77541d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(input_data_split, test_size=0.3333333, random_state=26)\n",
    "\n",
    "train_set_scaled, test_set_scaled = train_test_split(input_data_split_scaled, test_size=0.3333333, random_state=26)\n",
    "np.array(train_set_scaled).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6fd39",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e31571",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 128 # chunk size\n",
    "long = 128 # chunk size\n",
    "\n",
    "input_img = keras.Input(shape=(lat, long,1))\n",
    "\n",
    "x = layers.Conv2D(64,(16, 16), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (16, 16), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (16, 16), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(8, (16, 16), activation='relu', padding='same')(x)\n",
    "encoded = layers.Conv2D(4, (16, 16), activation='relu',strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(8, (2, 2), strides=(1, 1),activation='relu', padding='same')(encoded)\n",
    "x = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (2, 2), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (2, 2), strides=(1, 1),activation='relu', padding='same')(x)\n",
    "# x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "decoded = layers.Conv2DTranspose(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f45beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_set_scaled, train_set_scaled,\n",
    "                epochs=15, validation_data=(test_set_scaled, test_set_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_index = 122\n",
    "\n",
    "# select a sample\n",
    "original_data = test_set[test_sample_index]\n",
    "original_data.shape\n",
    "\n",
    "test_data = (original_data - min_value)/(max_value - min_value) # preprocessing\n",
    "test_data.shape\n",
    "\n",
    "decoded_data = autoencoder.predict(np.expand_dims(test_data, 0)) \n",
    "decoded_data = decoded_data*(max_value-min_value) + min_value   # scale back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce65530",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,32)) # image\n",
    "ax1 = fig.add_subplot(1,2,1) \n",
    "ax1.imshow(original_data,cmap='hot')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(decoded_data.reshape(128,128),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c654182",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.square((original_data-decoded_data)).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_index = 110\n",
    "\n",
    "# select a sample\n",
    "original_data = test_set[test_sample_index]\n",
    "original_data.shape\n",
    "\n",
    "test_data = (original_data - min_value)/(max_value - min_value) # preprocessing\n",
    "test_data.shape\n",
    "\n",
    "decoded_data = autoencoder.predict(np.expand_dims(test_data, 0)) \n",
    "decoded_data = decoded_data*(max_value-min_value) + min_value   # scale back\n",
    "\n",
    "fig = plt.figure(figsize=(16,32)) # image\n",
    "ax1 = fig.add_subplot(1,2,1) \n",
    "ax1.imshow(original_data,cmap='hot')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(decoded_data.reshape(128,128),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83baae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.square((original_data-decoded_data)).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder(32,32,4) layer(7-6) sample(3000 single region) kernelSize(16 & 2)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
