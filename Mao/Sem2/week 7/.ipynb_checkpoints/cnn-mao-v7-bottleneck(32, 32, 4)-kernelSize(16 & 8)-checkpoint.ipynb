{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51d6bcd",
   "metadata": {},
   "source": [
    "## Important parameters\n",
    "<br>xt_ocean: longitude, length 3600\n",
    "<br>yt_ocean: latitude, length 1500\n",
    "<br> [mind map](https://miro.com/app/board/o9J_lM4N1Pg=/?fromRedirect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1795d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "from tensorflow import keras\n",
    "import xarray,numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e6d28",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6208fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "input_data_split = []\n",
    "for np_name in glob.glob('../raw data/128/dataset_128_N102/*.np[yz]'):\n",
    "    input_data_split.append(np.load(np_name))\n",
    "input_data_split = np.array(input_data_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2f7c3",
   "metadata": {},
   "source": [
    "# Fix Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca0c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_value(input_data):\n",
    "    \"\"\"\n",
    "    input 3d matrix\n",
    "    \"\"\"\n",
    "    for i in range(0,len(input_data)):\n",
    "        arr = input_data[i]\n",
    "        arr[np.isnan(arr)] = 0\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dce738",
   "metadata": {},
   "source": [
    "# Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba3d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(input_data, max_value, min_value):\n",
    "    \"\"\"\n",
    "    input 3d matrix\n",
    "    \"\"\"\n",
    "    for i in range(len(input_data)):\n",
    "        input_data[i] = (input_data[i] - min_value)/(max_value - min_value)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1f398",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a093197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 128, 128, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "n = 3000 # sample size\n",
    "random.seed(7)\n",
    "input_data_split = np.array(random.sample(input_data_split.tolist(),n))\n",
    "input_data_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d72e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_split = fix_missing_value(input_data_split)\n",
    "max_value = np.amax(input_data_split)\n",
    "min_value = np.amin(input_data_split)\n",
    "input_data_split_scaled = min_max_scale(input_data_split, max_value, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce44ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 128, 128, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_split_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c60c7",
   "metadata": {},
   "source": [
    "# split train set & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77541d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 128, 128, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(input_data_split, test_size=0.3333333, random_state=26)\n",
    "\n",
    "train_set_scaled, test_set_scaled = train_test_split(input_data_split_scaled, test_size=0.3333333, random_state=26)\n",
    "np.array(train_set_scaled).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6fd39",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e31571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        524320    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        131088    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 8)         32776     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 4)         8196      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 8)         520       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 16)        2064      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 32)      8224      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 128, 128, 64)      32832     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 64)      65600     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 128, 128, 1)       577       \n",
      "=================================================================\n",
      "Total params: 822,645\n",
      "Trainable params: 822,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lat = 128 # chunk size\n",
    "long = 128 # chunk size\n",
    "\n",
    "input_img = keras.Input(shape=(lat, long,1))\n",
    "\n",
    "x = layers.Conv2D(64,(16, 16), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (16, 16), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (16, 16), activation='relu', padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(8, (16, 16), activation='relu', padding='same')(x)\n",
    "encoded = layers.Conv2D(4, (16, 16), activation='relu',strides=(1,1), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(8, (4, 4), strides=(1, 1),activation='relu', padding='same')(encoded)\n",
    "x = layers.Conv2DTranspose(16, (4, 4), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, (4, 4), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (4, 4), strides=(1, 1), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (4, 4), strides=(1, 1),activation='relu', padding='same')(x)\n",
    "# x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2),activation='relu', padding='same')(x)\n",
    "decoded = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f45beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "63/63 [==============================] - 494s 8s/step - loss: 0.0187 - val_loss: 0.0058\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 504s 8s/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 498s 8s/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 495s 8s/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 495s 8s/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 486s 8s/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 503s 8s/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 490s 8s/step - loss: 0.0013 - val_loss: 8.8627e-04\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 487s 8s/step - loss: 0.0012 - val_loss: 7.8006e-04\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 484s 8s/step - loss: 7.7456e-04 - val_loss: 6.2387e-04\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 822s 13s/step - loss: 0.0010 - val_loss: 7.5673e-04\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 489s 8s/step - loss: 6.3529e-04 - val_loss: 7.9607e-04\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 486s 8s/step - loss: 5.9080e-04 - val_loss: 4.8066e-04\n",
      "Epoch 14/15\n",
      "33/63 [==============>...............] - ETA: 3:30 - loss: 5.5861e-04"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(train_set_scaled, train_set_scaled,\n",
    "                epochs=15, validation_data=(test_set_scaled, test_set_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_index = 122\n",
    "\n",
    "# select a sample\n",
    "original_data = test_set[test_sample_index]\n",
    "original_data.shape\n",
    "\n",
    "test_data = (original_data - min_value)/(max_value - min_value) # preprocessing\n",
    "test_data.shape\n",
    "\n",
    "decoded_data = autoencoder.predict(np.expand_dims(test_data, 0)) \n",
    "decoded_data = decoded_data*(max_value-min_value) + min_value   # scale back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce65530",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,32)) # image\n",
    "ax1 = fig.add_subplot(1,2,1) \n",
    "ax1.imshow(original_data,cmap='hot')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(decoded_data.reshape(128,128),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c654182",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.square((original_data-decoded_data)).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_index = 110\n",
    "\n",
    "# select a sample\n",
    "original_data = test_set[test_sample_index]\n",
    "original_data.shape\n",
    "\n",
    "test_data = (original_data - min_value)/(max_value - min_value) # preprocessing\n",
    "test_data.shape\n",
    "\n",
    "decoded_data = autoencoder.predict(np.expand_dims(test_data, 0)) \n",
    "decoded_data = decoded_data*(max_value-min_value) + min_value   # scale back\n",
    "\n",
    "fig = plt.figure(figsize=(16,32)) # image\n",
    "ax1 = fig.add_subplot(1,2,1) \n",
    "ax1.imshow(original_data,cmap='hot')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(decoded_data.reshape(128,128),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83baae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.square((original_data-decoded_data)).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder(32,32,4) layer(7-6) sample(3000 single region) kernelSize(16 & 4)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
