{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 128 # chunk size 256,512\n",
    "long = 128 # chunk size 256,512\n",
    "def split_array(input_data, lat, long,region=100):\n",
    "    \"\"\"\n",
    "    Split the whole 3600*1500 array into smaller chunks.\n",
    "    Padding with zeros to make the array be divisible by chunk size.\n",
    "    \n",
    "    Args:\n",
    "        input_data: data of a single day from a eta_t instance\n",
    "        lat: chunk size\n",
    "        long: chunk size\n",
    "    \"\"\"\n",
    "    pad_cols = math.ceil(3600/long)*long - 3600 # number of zero columns adding to the right\n",
    "    pad_rows = math.ceil(1500/lat)*lat - 1500 # number of zero rows adding to the bottom\n",
    "    \n",
    "\n",
    "    input_data=np.pad(input_data,((0,pad_rows),(0,pad_cols)), 'constant',constant_values=(0,0)) # padding with zeros, right & bottom\n",
    "    \n",
    "    l = np.array_split(input_data,len(input_data)/lat,axis=0)\n",
    "    input_data_split = []\n",
    "    for i in range(len(l)):\n",
    "        dd = np.array_split(l[i],len(input_data[0])/long,axis=1)\n",
    "        input_data_split += dd\n",
    "    input_data_split = np.array(input_data_split)\n",
    "    return input_data_split[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [18:03<00:00, 90.28s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [15:11<00:00, 75.94s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [17:05<00:00, 85.45s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [17:07<00:00, 85.59s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [15:51<00:00, 79.26s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [18:58<00:00, 94.88s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [23:28<00:00, 117.40s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [20:10<00:00, 100.91s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [21:50<00:00, 109.22s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [22:05<00:00, 110.44s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [20:46<00:00, 103.88s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [20:18<00:00, 101.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [19:22<00:00, 96.90s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [21:12<00:00, 106.02s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [21:30<00:00, 107.52s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [21:42<00:00, 108.58s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [26:30<00:00, 132.55s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [25:07<00:00, 125.66s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 12/12 [23:17<00:00, 116.45s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [18:19<00:00, 91.65s/it]\n"
     ]
    }
   ],
   "source": [
    "folder = 'dataset3_102' #change folder name for every region\n",
    "num_of_years = 20\n",
    "region = 102 #change region\n",
    "num_errors = 0\n",
    "error_year = []\n",
    "error_month = []\n",
    "\n",
    "basic_url = 'http://dapds00.nci.org.au/thredds/dodsC/gb6/BRAN/BRAN_2016/OFAM/ocean_eta_t_'\n",
    "year = 1993\n",
    "for i in range(num_of_years):\n",
    "  year += 1\n",
    "  month = 0\n",
    "  for j in tqdm(range(12)):\n",
    "    month += 1\n",
    "    if month > 9:\n",
    "      m = str(month)\n",
    "    else:\n",
    "      m = '0'+str(month)\n",
    "    #print('year: ',year,' month: ',month)\n",
    "    y = str(year)\n",
    "    url = basic_url + y + '_' + m + '.nc'\n",
    "    try:\n",
    "        #data = nc.Dataset(url)\n",
    "        data = xr.open_dataset(url)\n",
    "    except:\n",
    "        num_errors+=1\n",
    "        error_year.append(y)\n",
    "        error_month.append(m)\n",
    "        continue\n",
    "    #variables = data.variables\n",
    "    eta_t = data['eta_t'].to_numpy() #data['eta_t'][:]\n",
    "    size = eta_t.shape[0]\n",
    "    for i in range(size):\n",
    "      eta_t_day_i = eta_t[i]\n",
    "      eta_t_numpy = eta_t_day_i #np.array(eta_t_day_i)\n",
    "      inputs = split_array(eta_t_numpy,lat,long,region)\n",
    "      inputsx = np.expand_dims(inputs,axis=2)\n",
    "      file_name = './'+folder+'/128x128_'+y+'_'+m+'_'+str(i+1)+'.npy'\n",
    "      np.save(file_name,inputsx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
